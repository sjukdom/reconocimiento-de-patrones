{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final: segmentación semántica usando Unet \n",
    "Se utiliza la red neuronal convolucional Unet que proporciona el modulo tf_net..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from tf_unet import unet, util, image_util\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "test_data = []\n",
    "\n",
    "len_training = 2975\n",
    "len_test = 500\n",
    "\n",
    "for i in range(len_training):\n",
    "    im = cv2.imread('dataset/train/' + str(i+1) + '.jpg', 1)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = im/255\n",
    "    training_data.append(im)\n",
    "\n",
    "for i in range(len_test):\n",
    "    im = cv2.imread('dataset/train/' + str(i+1) + '.jpg', 1)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im =  im/255\n",
    "    test_data.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = 256\n",
    "x_training = np.array([training_data[i][:,:img_dim] for i in range(len_training)])\n",
    "y_training = np.array([training_data[i][:,img_dim:] for i in range(len_training)])\n",
    "\n",
    "x_test = np.array([test_data[i][:,:img_dim] for i in range(len_test)])\n",
    "y_test = np.array([test_data[i][:,img_dim:] for i in range(len_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12)).suptitle('Imagenes de entrenamiento', fontsize=22)\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    if (i+1)%2!=0:\n",
    "        plt.imshow(x_training[i])\n",
    "    else:\n",
    "        plt.imshow(y_training[i-1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_provider = image_util.ImageDataProvider(\"dataset/train/*.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de la red neuronal Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Dropout, Activation, Flatten, MaxPooling2D, UpSampling2D, Input, merge\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 5\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "pool_stride = (2, 2)\n",
    "ups_size = (2, 2)\n",
    "input_shape = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defininir la arquitectura de la red neuronal \n",
    "La arquitectura de la red neuronal es como se muestra en la siguiente imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"imgs/u-net-architecture.png\", width=512, height=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante el modulo Keras se implementará la red, añadiendo cada una de las capas y conectandolas entre si.\n",
    "\n",
    "La red neuronal se divide en 3 partes:\n",
    "\n",
    "1. Codificación (4 etapas): Consiste de 2 operaciones de convolución y una de max pooling.\n",
    "2. Cuello de botella (1 etapa): Consiste de 2 operaciones de convolucion y una de up sampling.\n",
    "3. Decodificación (4 etapas): Consiste en concatenar las convoluciones finales de cada etapa con la salida que produce el up sampling, para posteriormente aplicar 2 convoluciones y un up sampling.\n",
    "\n",
    "Adicionalmente, se agregaran 2 capas de dropout con el fin de evitar que haya overfitting en el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
    "conv1 = Conv2D(64, 3, padding='same', activation='relu')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=pool_size, strides=pool_stride)(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, kernel_size, padding='same', activation='relu')(pool1)\n",
    "conv2 = Conv2D(128, kernel_size, padding='same', activation='relu')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=pool_size, strides=pool_stride)(conv2)\n",
    "\n",
    "conv3 = Conv2D(256, kernel_size, padding='same', activation='relu')(pool2)\n",
    "conv3 = Conv2D(256, kernel_size, padding='same', activation='relu')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=pool_size, strides=pool_stride)(conv3)\n",
    "\n",
    "conv4 = Conv2D(512, kernel_size, padding='same', activation='relu')(pool3)\n",
    "conv4 = Conv2D(512, kernel_size, padding='same', activation='relu')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)       # Dropout\n",
    "pool4 = MaxPooling2D(pool_size=pool_size, strides=pool_stride)(drop4)\n",
    "\n",
    "# Cuello de botella\n",
    "conv5 = Conv2D(1024, kernel_size, padding='same', activation='relu')(pool4)\n",
    "conv5 = Conv2D(1024, kernel_size, padding='same', activation='relu')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "upsa5 = Conv2D(512, 2, activation = 'relu', padding = 'same')(UpSampling2D(size=ups_size)(drop5))\n",
    "#upsa5 = UpSampling2D(size=ups_size, interpolation='nearest')(drop5)\n",
    "\n",
    "# Decoder\n",
    "\n",
    "merge6 = merge.concatenate([upsa5 , drop4], axis=3)\n",
    "conv6 = Conv2D(512, kernel_size, padding='same', activation='relu')(merge6)\n",
    "conv6 = Conv2D(512, kernel_size, padding='same', activation='relu')(conv6)\n",
    "upsa6 = Conv2D(256, 2, activation = 'relu', padding = 'same')(UpSampling2D(size=ups_size)(conv6))\n",
    "#upsa6 = UpSampling2D(size=ups_size)(conv6)\n",
    "\n",
    "merge7 = merge.concatenate([conv3, upsa6], axis=3)\n",
    "conv7 = Conv2D(256, kernel_size, padding='same', activation='relu')(merge7)\n",
    "conv7 = Conv2D(256, kernel_size, padding='same', activation='relu')(conv7)\n",
    "upsa7 = Conv2D(128, 2, activation = 'relu', padding = 'same')(UpSampling2D(size=ups_size)(conv7))\n",
    "#upsa7 = UpSampling2D(size=ups_size)(conv7)\n",
    "\n",
    "merge8 = merge.concatenate([conv2, upsa7], axis=3)\n",
    "conv8 = Conv2D(128, kernel_size, padding='same', activation='relu')(merge8)\n",
    "conv8 = Conv2D(128, kernel_size, padding='same', activation='relu')(conv8)\n",
    "upsa8 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size=ups_size)(conv8))\n",
    "#upsa8 = UpSampling2D(size=ups_size)(conv8)\n",
    "\n",
    "\n",
    "# Etapa final\n",
    "merge9 = merge.concatenate([conv1, upsa8], axis=3)\n",
    "conv9 = Conv2D(64, kernel_size, padding='same', activation='relu')(merge9)\n",
    "conv9 = Conv2D(64, kernel_size, padding='same', activation='relu')(conv9)\n",
    "conv9 = Conv2D(2, kernel_size, padding='same', activation='relu')(conv9)\n",
    "\n",
    "outputs = Conv2D(3, 1, activation='sigmoid')(conv9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn = keras.Model(input=inputs, output=outputs)\n",
    "cnn.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn.fit(x_training, y_training, batch_size=8, validation_split=0.05, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
